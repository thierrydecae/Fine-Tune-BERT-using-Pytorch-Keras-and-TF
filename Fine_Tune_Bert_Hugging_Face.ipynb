{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNMUkgHaLOW8AH3uQ5l9Cul",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thierrydecae/Fine-Tune-Bert/blob/main/Fine_Tune_Bert_Hugging_Face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SETUP"
      ],
      "metadata": {
        "id": "0RYBlWEC58Ve"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qgIsjCILwNh"
      },
      "outputs": [],
      "source": [
        "! pip install transformers\n",
        "! pip install -U accelerate\n",
        "! pip install -U transformers\n",
        "! pip install datasets\n",
        "! pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "UUrg_WNTiLz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "MuvnkxwLiy8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GET DATA"
      ],
      "metadata": {
        "id": "xLBx1L1c6Hfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def twenty_newsgroup_to_df(subset):\n",
        "    newsgroups = fetch_20newsgroups(subset=subset, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "    df = pd.DataFrame([newsgroups.data, newsgroups.target.tolist()]).T\n",
        "    df.columns = ['text', 'label']\n",
        "\n",
        "    targets = pd.DataFrame(newsgroups.target_names)\n",
        "    targets.columns=['label']\n",
        "\n",
        "    out = pd.merge(df, targets, left_on='label', right_index=True)\n",
        "    out['date'] = pd.to_datetime('now')\n",
        "    return out\n",
        "\n",
        "train=twenty_newsgroup_to_df('train')\n",
        "train=train[['text','label']]\n",
        "test=twenty_newsgroup_to_df('test')\n",
        "test=test[['text','label']]\n",
        "train.head()"
      ],
      "metadata": {
        "id": "TxSvkDxzfqiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOKENIZE DATA"
      ],
      "metadata": {
        "id": "W9S_fNwK6Mjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train.text.values]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "metadata": {
        "id": "LI-S3D9VjktV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 128"
      ],
      "metadata": {
        "id": "DL_lU5S_jPz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
      ],
      "metadata": {
        "id": "NceoQyx-ZVyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset.from_pandas(train)\n",
        "test_dataset = Dataset.from_pandas(test)\n",
        "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_test = test_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "YehLpMsumTqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_train_dataset = tokenized_train.shuffle(seed=42).select(range(1000))\n",
        "small_eval_dataset = tokenized_test.shuffle(seed=42).select(range(1000))"
      ],
      "metadata": {
        "id": "hzrdjcZhOEPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train with Pytorch"
      ],
      "metadata": {
        "id": "R1eJNMqiOJfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cats = len(train.label.unique())"
      ],
      "metadata": {
        "id": "435yEVPhk4jQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=num_cats)\n",
        "training_args = TrainingArguments(output_dir=\"test_trainer\",learning_rate =1e-5, num_train_epochs=5,evaluation_strategy=\"epoch\")\n",
        "metric = evaluate.load(\"accuracy\")"
      ],
      "metadata": {
        "id": "KRab-90dOLZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "pgo8vHwMOzkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train_dataset,\n",
        "    eval_dataset=small_eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "WO1VFyP7O73G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "qePzMsmtO-5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply on Test Set\n",
        "trainer.evaluate(small_eval_dataset)"
      ],
      "metadata": {
        "id": "QNKRQ7MEqskB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Model\n",
        "model.save_pretrained('./model/')"
      ],
      "metadata": {
        "id": "E3d2XVGlrbQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "new_model = AutoModelForSequenceClassification.from_pretrained('./model/').to(device)"
      ],
      "metadata": {
        "id": "EesWWuVfrqK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN WITH KERAS"
      ],
      "metadata": {
        "id": "HME94hv5AyOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = small_train_dataset"
      ],
      "metadata": {
        "id": "P1stcRfMA3DO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "tokenized_data = tokenizer(dataset[\"text\"], return_tensors=\"np\", padding=True)\n",
        "# Tokenizer returns a BatchEncoding, but we convert that to a dict for Keras\n",
        "tokenized_data = dict(tokenized_data)\n",
        "labels = np.array(dataset[\"label\"])"
      ],
      "metadata": {
        "id": "fkF8PCYJBa4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and compile our model\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\")\n",
        "# Lower learning rates are often better for fine-tuning transformers\n",
        "model.compile(optimizer=Adam(3e-5))\n",
        "model.fit(tokenized_data, labels)"
      ],
      "metadata": {
        "id": "E7rV5AFGBg6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN WITH TF"
      ],
      "metadata": {
        "id": "RUryGEDVE0X8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = small_train_dataset"
      ],
      "metadata": {
        "id": "0s-TTEJMFQgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_dataset(data):\n",
        "    return tokenizer(data[\"text\"])\n",
        "\n",
        "dataset = dataset.map(tokenize_dataset)"
      ],
      "metadata": {
        "id": "-JFRk0_gE2xH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_dataset = model.prepare_tf_dataset(dataset, batch_size=16, shuffle=True, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "seEEIlhlFLOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(3e-5))\n",
        "model.fit(tf_dataset)"
      ],
      "metadata": {
        "id": "CDFiudCNF5EI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}